{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.17-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1605843516857",
   "display_name": "Python 2.7.17 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from bq_helper import BigQueryHelper\n",
    "import math"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path of your credentials file (alternatively you can do this in your system path but I haven't had success)\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/keaton/carter/My Project-a95df9756ff9.json'\n",
    "\n",
    "bq_assistant = BigQueryHelper(\"bigquery-public-data\", \"epa_historical_air_quality\")\n",
    "\n",
    "STATES = ['Alabama','Alaska','Arizona','Arkansas','California','Colorado','Connecticut','Delaware','Florida','Georgia','Hawaii',\n",
    "'Idaho','Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana','Maine','Maryland','Massachusetts','Michigan','Minnesota',\n",
    "'Mississippi','Missouri','Montana','Nebraska','Nevada','New Hampshire','New Jersey','New Mexico','New York','North Carolina',\n",
    "'North Dakota','Ohio','Oklahoma','Oregon','Pennsylvania','Rhode Island','South Carolina','South Dakota','Tennessee',\n",
    "'Texas','Utah','Vermont','Virginia','Washington','West Virginia','Wisconsin','Wyoming'] \n",
    "\n",
    "FEATURES = ['o3','co','so2','no2','pm25_frm', 'pressure', 'temperature', 'wind']\n",
    "\n",
    "SAMPLE_DURATIONS = ['8-HR RUN AVG BEGIN HOUR','8-HR RUN AVG END HOUR', '3-HR BLK AVG', '1 HOUR', '24 HOUR', '1 HOUR', '1 HOUR', '1 HOUR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/home/keaton/.local/lib/python2.7/site-packages/ipykernel_launcher.py:25: PyarrowMissingWarning: Converting to a dataframe without pyarrow installed is often slower and will become unsupported in the future. Please install the pyarrow package.\n"
    }
   ],
   "source": [
    "# Set the path of your credentials file (alternatively you can do this in your system path but I haven't had success)\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/keaton/carter/My Project-a95df9756ff9.json'\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "query_job = client.query(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        state_name,\n",
    "        county_name,\n",
    "        year,\n",
    "        arithmetic_mean as measurement\n",
    "    FROM\n",
    "      `bigquery-public-data.epa_historical_air_quality.air_quality_annual_summary`\n",
    "    WHERE\n",
    "      parameter_name = \"PM2.5 - Local Conditions\"\n",
    "      AND sample_duration = \"24 HOUR\"\n",
    "      AND units_of_measure = \"Micrograms/cubic meter (LC)\"\n",
    "      AND poc = 1\n",
    "      AND pollutant_standard = \"PM25 Annual 2006\"\n",
    "    ORDER BY year\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "aqi_data = query_job.result().to_dataframe() # .to_dataframe() converts to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method for itterating through querries\n",
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method for ensuring all dataframes have the same index\n",
    "def fillIndex(data):\n",
    "\n",
    "    X = data.copy()\n",
    "\n",
    "    temp = []\n",
    "    for i in range(50):\n",
    "        temp.append(np.nan)\n",
    "\n",
    "    for year in range(1990,2020):\n",
    "        if not (year in X.index):\n",
    "            X.loc[year] = temp\n",
    "\n",
    "    X = X.sort_index(ascending = True)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method for combining dataframes\n",
    "def unifyDataFrames(df1, df2, df3):\n",
    "    df1copy = np.array(fillIndex(df1))\n",
    "    df2copy = np.array(fillIndex(df2))\n",
    "    df3copy = np.array(fillIndex(df3))\n",
    "\n",
    "    for i in range(len(df1copy)-1):\n",
    "        for j in range(len(df1copy[0])-1):\n",
    "            if math.isnan(df1copy[i][j]):\n",
    "                if not(math.isnan(df2copy[i][j])):\n",
    "                       df1copy[i][j] = df2copy[i][j]\n",
    "                elif not(math.isnan(df3copy[i][j])):\n",
    "                        df1copy[i][j] = df3copy[i][j]\n",
    "\n",
    "    return pd.DataFrame(df1copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dataframe with the average measurement of a feature per year for each state\n",
    "def averagePollutants(featureList, stateList, poc, sample_durations):\n",
    "    QUERY = \"\"\"\n",
    "    SELECT EXTRACT(YEAR FROM feature.date_local) as Year , AVG(feature.arithmetic_mean) as STitle\n",
    "    FROM\n",
    "      `bigquery-public-data.epa_historical_air_quality.feature_daily_summary` as feature\n",
    "      WHERE feature.poc = NUM AND  feature.state_name = 'State' AND feature.sample_duration = 'LENGTH'\n",
    "    GROUP BY Year\n",
    "    ORDER BY Year ASC\n",
    "        \"\"\"\n",
    "    dict_pol={}\n",
    "    counter = 0\n",
    "    for f in featureList : \n",
    "        dict_pol[f] = None \n",
    "        for s in stateList :\n",
    "            dic = {\"State\": s, \"feature\": f, \"STitle\": s.replace(' ', '_'), \"NUM\":str(poc), \"LENGTH\": sample_durations[counter]}\n",
    "            query = replace_all(QUERY, dic)\n",
    "            temp = bq_assistant.query_to_pandas(query).set_index('Year')\n",
    "            dict_pol[f] = pd.concat([dict_pol[f], temp], axis=1, sort=False)\n",
    "        counter += 1\n",
    "    \n",
    "    return dict_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates dataframes for the average feature per year in each state for different poc\n",
    "averageFeatureDF1 = averagePollutants(FEATURES, STATES, 1, SAMPLE_DURATIONS)\n",
    "averageFeatureDF2 = averagePollutants(FEATURES, STATES, 2, SAMPLE_DURATIONS)\n",
    "averageFeatureDF3 = averagePollutants(FEATURES, STATES, 3, SAMPLE_DURATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines average feature dataframes to fill in holes caused by using different poc\n",
    "finalFeatureAverages = {}\n",
    "for f in FEATURES:\n",
    "    finalFeatureAverages[f] = None\n",
    "    temp = unifyDataFrames(averageFeatureDF1[f], averageFeatureDF2[f], averageFeatureDF3[f])\n",
    "    finalFeatureAverages[f] = pd.concat([finalFeatureAverages[f], temp], axis=1, sort=False)\n",
    "for f in FEATURES:\n",
    "    filename = f +'.csv'\n",
    "    finalFeatureAverages[f].to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "honeyData = pd.read_csv (r'honeyproduction.csv')\n",
    "\n",
    "states = [\"AL\",\"AK\",\"AZ\",\"AR\",\"CA\",\"CO\",\"CT\",\"DE\",\"FL\",\"GA\",\"HI\",\"ID\",\"IL\",\"IN\",\"IA\",\"KS\",\"KY\",\"LA\",\"ME\",\"MD\",\"MA\",\"MI\",\"MN\",\"MS\",\"MO\",\"MT\",\"NE\",\"NV\",\"NH\",\"NJ\",\"NM\",\"NY\",\"NC\",\"ND\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\"TN\",\"TX\",\"UT\",\"VT\",\"VA\",\"WA\",\"WV\",\"WI\",\"WY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reads in honey data csv, formats data, adds honey to other features\n",
    "processedHoneyData = []\n",
    "for y in range(1990,1998):\n",
    "    yearRow = []\n",
    "    for s in states:\n",
    "        yearRow.append(np.nan)\n",
    "    processedHoneyData.append(yearRow)\n",
    "\n",
    "for y in range(1998,2013):\n",
    "    groupedYear = honeyData[honeyData['year']==y]\n",
    "    groupedYear = groupedYear.loc[:,['state', 'yieldpercol']] \n",
    "    rawHoneyData = np.array(groupedYear).T\n",
    " \n",
    "    yearRow = []\n",
    "    for s in states:\n",
    "        if s in rawHoneyData[0]:\n",
    "            yearRow.append( (int(groupedYear[groupedYear['state']==s].yieldpercol)))\n",
    "        else:\n",
    "            yearRow.append(np.nan)\n",
    "    processedHoneyData.append(yearRow)\n",
    "\n",
    "for y in range(2013,2020):\n",
    "    yearRow = []\n",
    "    for s in states:\n",
    "        yearRow.append(np.nan)\n",
    "    processedHoneyData.append(yearRow)\n",
    "processedHoneyData = pd.DataFrame(processedHoneyData)\n",
    "finalFeatureAverages['honey'] = None\n",
    "finalFeatureAverages['honey'] = pd.concat([finalFeatureAverages['honey'], processedHoneyData], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reformats data into feature vectors\n",
    "rawData = []\n",
    "for f in range(8):\n",
    "    rawData.append(np.array(finalFeatureAverages[FEATURES[f]]))\n",
    "rawData.append(np.array(finalFeatureAverages['honey']))\n",
    "rawData = np.array(rawData)\n",
    "\n",
    "featureVectors = []\n",
    "for i in range(len(rawData[0])-1):\n",
    "    for j in range(len(rawData[0][0])-1):\n",
    "        if not (np.isnan(np.sum(rawData[:,i,j]))):\n",
    "            featureVectors.append(rawData[:,i,j])\n",
    "        \n",
    "featureVectors = np.array(featureVectors)\n",
    "\n",
    "pd.DataFrame(featureVectors).to_csv('completeFeatureVectors.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}