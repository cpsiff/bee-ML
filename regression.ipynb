{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "This notebook performs linear regression on our honey production and air quality combined dataset, which is read in in the second cell<br>\n",
    "We use the matrix solution to minimize the MSE<br>\n",
    "Cross validation is performed and an MSE is output near the end. Everything is written from scratch with numpy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/completeFeatureVectors.csv\")\n",
    "\n",
    "X = data[['o3','co','so2','no2','pm25_frm', 'pressure', 'temperature', 'wind', 'year']].to_numpy()\n",
    "# subtract 1998 from the year so that it starts at zero\n",
    "X[:,8] = X[:,8]-1998\n",
    "# Append ones to the start of X for the bias term\n",
    "X = np.append(np.ones((X.shape[0],1)), X, axis=1)\n",
    "y = data[['yield_per_col']].to_numpy()"
   ]
  },
  {
   "source": [
    "Minimize the MSE by using the matrix formula to find theta.<br>\n",
    "Also find the variance sigma so that we can find confidence intervals for our predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "intercept: 120.190591\no3: -544.230626\nco: -20.476653\nso2: 0.998524\nno2: 0.152943\npm25_frm: -0.686405\npressure: 0.002974\ntemperature: 0.317392\nwind: -0.375663\nyear: -1.848450\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True) # disable scientific notation when printing\n",
    "\n",
    "theta = np.matmul(np.matmul(np.linalg.inv(np.matmul(X.T, X)),X.T),y)\n",
    "\n",
    "# print out theta with labels\n",
    "for label,theta_i in zip(['intercept','o3','co','so2','no2','pm25_frm','pressure','temperature','wind','year'], theta):\n",
    "    print(label + \": \" + \"{:f}\".format(theta_i[0]))"
   ]
  },
  {
   "source": [
    "Make a prediction and show a 95% confidence interval for that prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "prediction: 28.046243398850937\ndev: 190.05662274680785\nppf: 372.50413560705937\nrange: 5076.42310982046\n95% conf. Lower bound: -5048.3768664216095\n95% conf. Upper bound: 5104.4693532193105\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1],[0.0312],[0.759],[1.575],[14.757],[43.9],[984.],[59.17],[97.27], [10]])\n",
    "prediction = np.matmul(x.T, theta)[0][0]\n",
    "print(\"prediction:\", prediction)\n",
    "\n",
    "# find variance sigma and find a 95% confidence interval\n",
    "sigma_sq = (np.matmul((y-np.matmul(X, theta)).T,(y-np.matmul(X, theta))) / X.shape[0]-1)[0][0]\n",
    "sigma = math.sqrt(sigma_sq)\n",
    "dev = sigma_sq*np.matmul(np.matmul(x.T,np.linalg.inv(np.matmul(X.T,X))),x)[0][0]\n",
    "print(\"dev:\", dev) # getting 190... seems very high, not sure how to confirm\n",
    "ppf = norm.ppf(0.975, loc=0, scale=dev) # how ppf works: https://stackoverflow.com/questions/60699836/how-to-use-norm-ppf\n",
    "print(\"ppf:\", ppf)\n",
    "rng = ppf*sigma # ppf returns a standard deviation multiplier, so we need to multiply by the stdev to get the true value\n",
    "\n",
    "print(\"range:\", rng)\n",
    "print(\"95% conf. Lower bound:\", prediction-rng)\n",
    "print(\"95% conf. Upper bound:\", prediction+rng)"
   ]
  },
  {
   "source": [
    "Determine which features are significant using the inverse tail of chi squared function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0: intercept: significant\n1: o3: not significant\n2: co: significant\n3: so2: significant\n4: no2: significant\n5: pm25_frm: significant\n6: pressure: significant\n7: temperature: significant\n8: wind: significant\n9: year: significant\n"
     ]
    }
   ],
   "source": [
    "cov_matrix = sigma_sq*np.linalg.inv(np.matmul(X.T,X))\n",
    "threshold = 0.2357 # inverse tail of chi squared(?) function\n",
    "features = ['intercept','o3','co','so2','no2','pm25_frm','pressure','temperature','wind','year']\n",
    "for i in range(theta.shape[0]):\n",
    "    sig = (theta[i,:][0] / cov_matrix[i,i])**2\n",
    "    if sig > threshold:\n",
    "        print(str(i) + \": \" + features[i] + \": significant\")\n",
    "    else:\n",
    "        print(str(i) + \": \" + features[i] + \": not significant\")"
   ]
  },
  {
   "source": [
    "Perform k-fold cross validation to find our mean squared error (MSE)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean squared error: 208.7902477777134\nMean absolute error: 11.246244252785345\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "# the size of the testing set for each fold\n",
    "chunk_size = X.shape[0] // k\n",
    "\n",
    "# shuffle X and y together\n",
    "Xy_shuffled = np.append(X, y, axis=1)\n",
    "np.random.shuffle(Xy_shuffled)\n",
    "\n",
    "sq_errors = []\n",
    "abs_errors = []\n",
    "\n",
    "# iterate through k folds\n",
    "for i in range(k):\n",
    "\n",
    "    # split out testing and training data\n",
    "    X_k_test = Xy_shuffled[chunk_size*i:chunk_size*(i+1),:10]\n",
    "    y_k_test = Xy_shuffled[chunk_size*i:chunk_size*(i+1),10]\n",
    "\n",
    "    if i == 0:\n",
    "        X_k_train = Xy_shuffled[chunk_size:,:10]\n",
    "        y_k_train = Xy_shuffled[chunk_size:,10]\n",
    "    elif i == k-1:\n",
    "        X_k_train = Xy_shuffled[:chunk_size*i,:10]\n",
    "        y_k_train = Xy_shuffled[:chunk_size*i,10]\n",
    "    else:\n",
    "        X_k_train = np.append(Xy_shuffled[:chunk_size*i,:10], Xy_shuffled[chunk_size*(i+1):,:10], axis=0)\n",
    "        y_k_train = np.append(Xy_shuffled[:chunk_size*i,10], Xy_shuffled[chunk_size*(i+1):,10], axis=0)\n",
    "\n",
    "    # train on training data to get theta_k\n",
    "    theta_k = np.matmul(np.matmul(np.linalg.inv(np.matmul(X_k_train.T, X_k_train)),X_k_train.T),y_k_train)\n",
    "    # test out the theta_k that we found on the testing chunk\n",
    "    for i in range(X_k_test.shape[0]):\n",
    "        y_pred = np.matmul(X_k_test[i,:].T, theta_k)\n",
    "        y_actual = y_k_test[i]\n",
    "        #print(\"predicted:\", y_pred, \"actual\", y_actual)\n",
    "        sq_errors.append((y_pred - y_actual)**2)\n",
    "        abs_errors.append(abs(y_pred-y_actual))\n",
    "    \n",
    "mean_sq_error = np.mean(sq_errors)\n",
    "mean_abs_error = np.mean(abs_errors)\n",
    "print(\"Mean squared error:\", mean_sq_error)\n",
    "print(\"Mean absolute error:\", mean_abs_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}